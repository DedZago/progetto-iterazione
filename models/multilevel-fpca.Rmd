---
title: "Modellazione multilevel con componenti principali funzionali"
author: "Daniele Zago, Simon Mazzarolo, Silvia Brosolo, Emanuele Donà"
date: "2021-04-28"
output: 
    pdf_document:
        dev: png
        extra_dependencies: ["bm"]
        df_print: kable
        latex_engine: xelatex
---

```{r multilevel-base_setup, cache=FALSE, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, engine.opts='-l', tidy=FALSE, fig.width=16, fig.height=10, dpi = 200)
knitr::knit_hooks$set(inline=function(x) prettyNum(round(x,2)))
setwd("~/Documents/git/progetto-iterazione/models/")
load("../data/mandarino-proc.RData")
```

```{r libs, message=FALSE}
library(rstanarm)
library(bayesplot)
library(tidybayes)
library(ggplot2)
library(magrittr)
library(lme4)
library(dplyr)
library(gtools)
library(tidyverse)
```

# Preprocessing #

Costruiamo il dataset in formato "largo" per la stima delle fPCA:
```{r fpca_data}
mandarino_wide = spread(mandarino[ , -6 ], time, "f0")
Y = as.matrix(mandarino_wide[ , 5:(NCOL(mandarino_wide)) ])     # Funzioni osservate

mandarino$peak = ifelse(mandarino$time >= 7 & mandarino$time <= 13, 1, 0)
```

# Analisi con componenti principali funzionali (fPCA)#

```{r fpca_fve, echo=FALSE}
# Threshold di varianza per le fPCA
fve = 0.99
```

Stima delle funzioni principali che spieghino il `r 100*fve`\% della varianza funzionale:

```{r fpca_base}

library(fdapace)

Y_list = lapply(seq_len(NROW(Y)), function(i) Y[i,])
t_list = lapply(seq_len(NROW(Y)), function(i) 1:20)

fpca = FPCA(Ly = Y_list, Lt = t_list, optns = list(FVEthreshold = fve))
K = fpca$selectK

ypred = predict(fpca, Y_list, t_list)
{
    # Confronto curve osservate con ricostruite tramite fPCA
    par(mfrow = c(2,1))
    matplot(t(Y), type = "l", main = "Funzioni osservate")
    matplot(t(ypred$predCurves), type = "l",
            main = paste0("Funzioni ricostruite con ", K, " fPC"))
    par(mfrow = c(1,1))
}

# Autofunzioni stimate
eigenFPCA = fpca$phi                                 
matplot(eigenFPCA, type = "l", main = "Funzioni principali")
legend("topleft", legend=paste0("fPC ", 1:K), col=1:K,cex=0.8, fill=1:K)

# Aggiungo le autofunzioni come covariate al dataset
eigenColumns = NULL
for(i in 1:NROW(Y)){
    eigenColumns = rbind(eigenColumns, eigenFPCA)
}

mandarino_fpca = cbind(mandarino, eigenColumns)
colnames(mandarino_fpca) = c(colnames(mandarino), paste0("PC", 1:K))
```

Verifico che la variabilità delle componenti principali non sia eccessiva, in modo che il modello successivo non stia "barando" nell'utilizzare le fpca stimate:
```{r fpca_var}
fpca_list = vector(mode = "list", length = length(unique(mandarino$subject)))
i = 1
for(subj in unique(mandarino$subject)){
    idx = mandarino_wide$subject == subj
    Y_sub = as.matrix(mandarino_wide[!idx , 5:(NCOL(mandarino_wide)) ])             # funzioni senza il soggetto
    Y_list_sub = lapply(seq_len(NROW(Y_sub)), function(i) Y_sub[i,])
    t_list_sub = lapply(seq_len(NROW(Y_sub)), function(i) 1:20)
    fpca_list[[i]] = FPCA(Ly = Y_list_sub, Lt = t_list_sub, optns = list(FVEthreshold = fve))
    i = i+1
}

plot_phi_list = function(fpca_list, m = 1){
    # Plot delle funzioni principali sovrapposte da una lista di oggetti fpca
    #
    # @param fpca_list: lista di fpca
    # @param m: ordine della funzione principale da plottare
    #
    # @return oggetto plot contenente il grafico sovrapposto delle fpc
    
    ymax = max(unlist(lapply(fpca_list, function(obj) max(obj$phi))))
    ymin = min(unlist(lapply(fpca_list, function(obj) min(obj$phi))))

    plot(fpca_list[[1]]$obsGrid, ylim = c(ymin, ymax), type = "n", xlab = "t", ylab = "f0", main = paste0("fPC ", m))
    for(i in 1:length(fpca_list)){
        lines(fpca_list[[i]]$obsGrid, fpca_list[[i]]$phi[ , m ])
    }
}

par(mfrow = c(2,2))
plot_phi_list(fpca_list, 1)
plot_phi_list(fpca_list, 2)
plot_phi_list(fpca_list, 3)
plot_phi_list(fpca_list, 4)
par(mfrow = c(1,1))

```


```{r pred_plot, echo=FALSE}
# --------------------------------------------
# Funzioni per fare i grafici delle previsioni
# --------------------------------------------
ppc_subject = function(subj, dati, ypred, ci.low = NULL, ci.upper = NULL){
    # Plot frequency profiles (f_0) for an individual subject with predictions
    #
    # @param subj: string containing subject identifier, e.g. "S10"
    # @param datiPred: dataset with an additional `ypred` column
    #
    # @return ggplot2 object, plot with average effect over different repetitions

    if(!subj %in% levels(dati$subject)) stop("Subject not found")
    brks  = c("y", "E(yrep|y)")

    datiPred = cbind(dati, "ypred" = ypred)
    if(!is.null(ci.low) & !is.null(ci.upper)){
        datiPred = cbind(datiPred, "ci.low" = ci.low, "ci.upper" = ci.upper)
        datiPred %>%
            subset(subject == subj) %>%
            ggplot(aes(time))+
            geom_line(aes(y = f0, colour = brks[1]), alpha=0.9) + 
            geom_line(aes(y = ypred, colour = brks[2])) + 
            scale_colour_manual("", 
                      breaks = brks,
                      values = c("black", "blue")) +
            geom_ribbon(aes(ymin = ci.low, ymax = ci.upper), alpha=0.2) +
            facet_grid(cog_load ~  syllable1*syllable2)
    } else{
        datiPred %>%
            subset(subject == subj) %>%
            ggplot(aes(time))+
            geom_line(aes(y = f0), alpha=0.45) + 
            geom_line(aes(y = ypred), color = "darkblue") + 
            facet_grid(cog_load ~  syllable1*syllable2)
    }
}

ppc_full = function(dati, ypred){
    # Plot frequency profiles (f_0) for an individual subject with predictions
    #
    # @param subj: string containing subject identifier, e.g. "S10"
    # @param datiPred: dataset with an additional `ypred` column
    #
    # @return ggplot2 object, plot with average effect over different repetitions

    datiPred = cbind(dati, "ypred" = ypred)
    datiPred$subject = factor(datiPred$subject,
                               levels = mixedsort(levels(datiPred$subject)))

    datiPred %>%
        ggplot(aes(time))+
        geom_line(aes(y = f0, group = subject, color = subject), alpha=0.8, linetype = 2) + 
        geom_line(aes(y = ypred, group = subject, color = subject)) + 
        facet_grid(cog_load ~  syllable1*syllable2)
}
```

```{r stan_lme_fit}
if(file.exists("fitStanLmerFpca.Rdata")){
    load("fitStanLmerFpca.Rdata")
} else{
    fitStanLmerFpca = stan_glmer(f0 ~ cog_load + current +
                              PC1 + PC2 + PC3 + PC4 +
                              PC1:syllable1 + PC1:syllable2 +
                              PC2:syllable1 + PC2:syllable2 +
                              PC3:syllable1 + PC3:syllable2 +
                              PC4:syllable1 + PC4:syllable2 +
                              (1 | subject) +
                              (0 + current|subject) +
                              (0 + PC1 + PC2 + PC3 + PC4|subject) +
                              (0 + PC1:syllable1 | subject) +
                              (0 + PC1:syllable2 | subject) +
                              (0 + PC2:syllable1 | subject) +
                              (0 + PC2:syllable2 | subject) +
                              (0 + PC3:syllable1 | subject) +
                              (0 + PC3:syllable2 | subject) +
                              (0 + PC4:syllable1 | subject) +
                              (0 + PC4:syllable2 | subject) 
                              ,
                         data = mandarino_fpca,
                    algorithm = "meanfield",
                    iter = 20000,
                    QR = TRUE)
    save(fitStanLmerFpca, file="fitStanLmerFpca.Rdata")
}
summary(fitStanLmerFpca)
```

```{r stan_lme_ppc}
plot(fitStanLmerFpca, pars=names(fitStanLmerFpca$coefficients)[1:33])
```

```{r stan_lme_pred}
ypredStanLmerFpca = posterior_predict(fitStanLmerFpca, draws = 500)
ypred = apply(ypredStanLmerFpca, 2, mean)
stdev = apply(ypredStanLmerFpca, 2, sd)
lmin = apply(ypredStanLmerFpca, 2, function(col) quantile(col, p = 0.05))
lmax = apply(ypredStanLmerFpca, 2, function(col) quantile(col, p = 0.95))

ppc_subject("S1", mandarino, ypred, lmin, lmax)
ppc_subject("S2", mandarino, ypred, lmin, lmax)
ppc_subject("S3", mandarino, ypred, lmin, lmax)
ppc_subject("S4", mandarino, ypred, lmin, lmax)
# ppc_subject("S5", mandarino, ypred, lmin, lmax)
# ppc_subject("S6", mandarino, ypred, lmin, lmax)
# ppc_subject("S7", mandarino, ypred, lmin, lmax)
# ppc_subject("S8", mandarino, ypred, lmin, lmax)
# ppc_subject("S9", mandarino, ypred, lmin, lmax)
# ppc_subject("S10", mandarino, ypred, lmin, lmax)
# ppc_subject("S11", mandarino, ypred, lmin, lmax)
# ppc_subject("S12", mandarino, ypred, lmin, lmax)

ppc_full(mandarino, ypred)
```

## Selezione effetti fissi e casuali con LOOCV 

```{r effetti_fissi}
cores  = min(4, parallel::detectCores())
library(loo)

# Nel primo modello metto un po' di tutto
set.seed(123)
fitStanLmerFpca1 = stan_glmer(f0 ~ cog_load + current + peak + syllable1 + syllable2 + syllable1:syllable2 +
                              PC1 + PC2 + PC3 + PC4 +
                              PC1:syllable1 + PC1:syllable2 +
                              PC2:syllable1 + PC2:syllable2 +
                              PC3:syllable1 + PC3:syllable2 +
                              PC4:syllable1 + PC4:syllable2 +
                              (1 | subject) +
                              (0 + current|subject) +
                              (0 + PC1 + PC2 + PC3 + PC4|subject) +
                              (0 + PC1:syllable1 | subject) +
                              (0 + PC1:syllable2 | subject) +
                              (0 + PC2:syllable1 | subject) +
                              (0 + PC2:syllable2 | subject) +
                              (0 + PC3:syllable1 | subject) +
                              (0 + PC3:syllable2 | subject) +
                              (0 + PC4:syllable1 | subject) +
                              (0 + PC4:syllable2 | subject) 
                              ,
                         data = mandarino_fpca,
                    algorithm = "meanfield",
                    iter = 20000,
                    QR = TRUE)

save(fitStanLmerFpca1, file="fitStanLmerFpca1.Rdata")
summary(fitStanLmerFpca1)

loo1 <- loo(fitStanLmerFpca1, cores = cores) # warnings?
loo1$estimates
#k1 <- kfold(fitStanLmerFpca1, K = 10, cores = cores, verbose = T) RIP si impianta
```

