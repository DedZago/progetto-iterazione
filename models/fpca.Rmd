---
title: "Multilevel Functional PCA"
author: "Daniele Zago"
date: "2021-05-05"
output: 
    pdf_document:
        dev: png
        extra_dependencies: ["bm"]
        df_print: kable
        latex_engine: xelatex
---

```{r fpca_setup, cache=FALSE, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, engine.opts='-l', tidy=FALSE, fig.width=12, fig.height=8)
knitr::knit_hooks$set(inline=function(x) prettyNum(round(x,2)))
setwd("~/Documents/git/progetto-iterazione/models")
```

# FPCA multilevel #
Applico una decomposizione a valori singolari funzionale per dati multilevel

```{r data}
load("../data/mandarino.RData")
load("../data/mandarino-proc.RData")
library(refund)
library(tidyverse)

# Reshape dei dati in formato largo per le fPCA
mandarino = mandarino[ , -6 ]
mandarino_wide = spread(mandarino, time, "f0")

subj = as.numeric(mandarino_wide$subject)                       # Indicatore soggetti
Y = as.matrix(mandarino_wide[ , 5:(NCOL(mandarino_wide)) ])     # Funzioni osservate

if(file.exists("fpca.Rdata")){
    load("fpca.Rdata")
} else{
    fpca = mfpca.sc(Y, id = subj, twoway = TRUE, pve = 0.99)
    save(fpca, file="fpca.Rdata")
}

{
    par(mfrow = c(2,1))
    matplot(t(Y), type = "l")               # Plot delle funzioni osservate
    matplot(t(fpca$Yhat), type = "l")       # Plot delle funzioni ricostruite con fPCA
    par(mfrow = c(1,1))
}
```

```{r fpca}
fpca$npc            # numero componenti principali, level1: subject, level2: global
fpca$scores$level1  # pesi componenti principali soggettive
fpca$scores$level2  # pesi componenti principali globali
fpca$mu             # media globale
fpca$efunctions     # autofunzioni
fpca$evalues        # autovalori
fpca$sigma2         # errore di misurazione
fpca$eta            # shift dalla media per ogni soggetto
```

```{r fitScores}
library(glmnetUtils)

# Provo un modello lineare sugli scores delle eigenfunctions globali
fit = lm(scores2[ , 1 ] ~ cog_load + syllable1 + syllable2 + syllable1:syllable2, data = mandarino_wide)

# Siccome sono tanti parametri (6 funzioni * 17 covariate) uso elastic-net
X = model.matrix(scores2[ , 1 ] ~ cog_load + syllable1 + syllable2 + syllable1:syllable2, data = mandarino_wide)[ , -1 ]

# fitScores[[i]]: glmnet sugli scores della i-esima eigenfunction
fitScores = vector(mode = "list", length = NCOL(scores2))
for(i in 1:NCOL(scores2)){
    fitScores[[i]] = cv.glmnet(X, scores2[ , i ], alpha = 0.5) 
}
lapply(fitScores, coef)
```
